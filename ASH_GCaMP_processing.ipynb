{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KDTree\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "\n",
    "# Create a dictionary with key = eid, value = dataframe from each experiment. \n",
    "directory = r\"\"\n",
    "analysis_directory = directory + \"/analysis\" \n",
    "if not os.path.exists(analysis_directory):\n",
    "    os.makedirs(analysis_directory)\n",
    "add_to_filename = \"ASH_nlsGC6m\"              \n",
    "all_files = glob.glob(directory + \"/*.csv\")\n",
    "file_list = [] \n",
    "df_raw = {} # Dictionary of keys = file name, values = dataframe of raw csv.\n",
    "\n",
    "total_sec           = 25\n",
    "stim_on_sec         = 5 \n",
    "stim_off_sec        = 15\n",
    "frames_per_sec      = 10\n",
    "frame_rate          = 1/frames_per_sec\n",
    "frames              = np.arange(0, total_sec*frames_per_sec)\n",
    "\n",
    "\n",
    "def smooth (x,window_len=11,window='hanning'):\n",
    "        s = np.r_[2*x[0]-x[window_len-1::-1],x,2*x[-1]-x[-1:-window_len:-1]]\n",
    "        if window == 'flat': #moving average\n",
    "                w=np.ones(window_len,'d')\n",
    "        else:  \n",
    "                w=eval('np.'+window+'(window_len)')\n",
    "        y = np.convolve(w/w.sum(),s,mode='same')\n",
    "        return y[window_len:-window_len+1]\n",
    "\n",
    "## Go through each file in the directory to get data\n",
    "for i, file_name in enumerate (all_files):\n",
    "    file_name_cut = file_name[(len(directory)+1):-4]\n",
    "    file_list.append(file_name_cut)\n",
    "\n",
    "    df_raw[file_name_cut] = pd.read_csv(file_name, index_col=None, header=0)\n",
    "    \n",
    "    neuron          = np.array(df_raw[file_name_cut][\"Signal\"])\n",
    "    background      = np.array(df_raw[file_name_cut][\"BG\"])\n",
    "    neuron          = neuron[:250]\n",
    "    background      = background[:250]   \n",
    "    subtract        = neuron - background\n",
    "    F0              = np.median(subtract[40:49])  \n",
    "    dFF0            = (subtract - F0)/F0*100\n",
    "    \n",
    "    ## change to list \n",
    "    frame_list  = list(frames)    \n",
    "    dFF0        = list(dFF0)\n",
    "    sm_dFF0     = list(sm_dFF0)\n",
    "    \n",
    "    ## peak time is where the dFF0 is max after smoothing by 21.   \n",
    "    sm_dFF0_peak   = max(sm_dFF0) \n",
    "    peak_index     = sm_dFF0.index(sm_dFF0_peak)\n",
    "    time_peak      = frame_list[peak_index]/frames_per_sec\n",
    "                     \n",
    "## Re-arrange the dataframe according to the peak value\n",
    "df_dFF0_peak_sorted = df_dFF0_peak.sort_values(ascending = False)\n",
    "\n",
    "for i, file_name_cut in enumerate(df_dFF0_peak_sorted.index):\n",
    "    if i ==0:\n",
    "        df_dFF0_heatmap_sorted = pd.DataFrame(df_dFF0[file_name_cut], columns = [file_name_cut])\n",
    "        df_dFF0_scaled_sorted  = pd.DataFrame(df_dFF0_scaled[file_name_cut], columns = [file_name_cut])\n",
    "    else:\n",
    "        df_dFF0_heatmap_sorted[file_name_cut] = pd.Series(df_dFF0[file_name_cut])\n",
    "        df_dFF0_scaled_sorted[file_name_cut]  = pd.Series(df_dFF0_scaled[file_name_cut])\n",
    "      \n",
    "    \n",
    "df_dFF0_heatmap_sorted = df_dFF0_heatmap_sorted.T      \n",
    "df_dFF0_scaled_sorted  = df_dFF0_scaled_sorted.T\n",
    "\n",
    "## Heatmap same scale\n",
    "ax1 = plt.axes()\n",
    "sns.heatmap(df_dFF0_heatmap_sorted, xticklabels = 50, yticklabels=True, cmap=\"jet\", vmax=500, vmin=-50, ax = ax1)\n",
    "bottom, top = ax1.get_ylim()\n",
    "ax1.set_ylim(bottom + 0.5, top -0.5)\n",
    "ax1.set_title(\"%s dF/F0 n = %d\" % (add_to_filename, (i+1)))\n",
    "save_file_path = analysis_directory + \"/\" + add_to_filename + \"_heatmap_same_scale.png\"\n",
    "figure = ax1.get_figure() \n",
    "figure.savefig(save_file_path, dpi=1200)\n",
    "plt.show()\n",
    "\n",
    "# Calculate mean \n",
    "df_dFF0_values = df_dFF0.drop(columns=[\"frame\"])\n",
    "dFF0_mean      = df_dFF0_values.mean(axis=1)\n",
    "dFF0_stderr    = df_dFF0_values.std(axis=1)\n",
    "dFF0_stderr    = dFF0_stderr/math.sqrt(len(all_files))\n",
    "\n",
    "## Figure of mean trace with standard error, same scale\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.errorbar(frames/frames_per_sec, dFF0_mean, dFF0_stderr, linewidth = 2, color = \"black\", ecolor = \"lightgray\")    \n",
    "plt.ylim(-20, 250)\n",
    "plt.xlabel(\"time (sec)\")\n",
    "plt.ylabel(\"deltaF/F0 (%)\")\n",
    "plt.title(\"%s mean trace\" % add_to_filename)\n",
    "save_file_path = analysis_directory + \"/\" + add_to_filename + \"_mean_stderr_dFF0_same_scale.png\"\n",
    "plt.savefig(save_file_path)\n",
    "plt.show() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
